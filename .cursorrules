# Cursor AI Assistant Rules for Spawn App Back-End

## Test Organization Rules

### Avoid Creating New Test Files
- **DO NOT** create new test files unless absolutely necessary
- **ALWAYS** check if an appropriate existing test file exists first
- Add new tests to existing service test files whenever possible

### Test File Naming Convention
- Service tests should be named: `{ServiceName}Tests.java` (e.g., `OAuthServiceTests.java`, `UserServiceTests.java`)
- All service tests should be in the `src/test/java/com/danielagapov/spawn/ServiceTests/` directory

### When to Add Tests to Existing Files
- **Unit tests**: Add to the corresponding service test file (e.g., OAuth tests â†’ `OAuthServiceTests.java`)
- **Integration tests**: Add as inner static classes within the service test file with proper Spring annotations
- **Bug fix tests**: Add to the service test file that covers the component being fixed
- **Race condition tests**: Add to the service test file with appropriate concurrency testing setup

### When New Test Files Are Acceptable
Only create new test files when:
1. Testing a completely new service that doesn't have an existing test file
2. Creating controller-specific tests that don't fit in service tests
3. Testing complex integration scenarios that span multiple services and need their own setup

### Test Organization Within Files
- Group related tests together with descriptive comments
- Use inner static classes for integration tests that require different Spring context setup
- Maintain clear separation between unit tests (with mocks) and integration tests (with real dependencies)

## Code Organization Rules

### Service Layer
- Keep service interfaces lean and focused
- Use dependency injection consistently
- Handle transaction boundaries explicitly for data modification operations

### Repository Layer
- Use `@Modifying` and `@Query` for custom delete operations
- Always include `@Transactional` for modifying queries
- Prefer explicit queries over relying solely on cascade operations for critical data integrity

### Error Handling
- Use retry mechanisms with exponential backoff for transient errors
- Log warnings for recoverable errors, errors for unrecoverable issues
- Provide meaningful error messages that help with debugging

### Database Operations
- Explicitly handle race conditions in concurrent scenarios
- Use flush() when immediate persistence is required
- Prefer explicit deletion over cascade deletion for critical relationships

## Naming Conventions

### Test Methods
- Use descriptive names that explain the scenario: `testOAuthReRegistrationAfterIncompleteAccount()`
- Include the expected outcome: `testExplicitMappingDeletion()`
- Group by functionality with consistent prefixes

### Variables
- Use meaningful names that describe the data: `incompleteUser`, `externalId`, `mappingRepository`
- Avoid abbreviations unless they're domain-specific and well-known

### Comments
- Include bug report references when fixing specific issues
- Explain complex business logic with inline comments
- Document race condition handling and retry mechanisms 